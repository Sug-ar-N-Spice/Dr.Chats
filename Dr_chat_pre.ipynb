{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from typing import List, Dict\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "class STIDataPreprocessor:\n",
    "    \"\"\"\n",
    "    Preprocessor for Sexually Transmitted Infections (STI) medical data.\n",
    "    \n",
    "    This class handles cleaning, normalization, and preparation of text data\n",
    "    related to STIs for use in a medical chatbot.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the preprocessor with necessary NLTK downloads.\"\"\"\n",
    "        nltk.download('punkt', quiet=True)\n",
    "        nltk.download('stopwords', quiet=True)\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "        # STI-specific terms to keep even if they're in stopwords\n",
    "        self.sti_terms = {'hiv', 'aids', 'std', 'sti', 'hpv', 'hsv'}\n",
    "        self.stop_words = self.stop_words - self.sti_terms\n",
    "\n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Clean and normalize the input text.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Raw input text\n",
    "        \n",
    "        Returns:\n",
    "            str: Cleaned and normalized text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove special characters but keep medical symbols\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s+\\-/%]', '', text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        return text\n",
    "\n",
    "    def remove_stopwords(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Remove stopwords from the text, keeping STI-specific terms.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Input text\n",
    "        \n",
    "        Returns:\n",
    "            str: Text with stopwords removed\n",
    "        \"\"\"\n",
    "        words = word_tokenize(text)\n",
    "        filtered_words = [word for word in words if word.lower() not in self.stop_words]\n",
    "        return ' '.join(filtered_words)\n",
    "\n",
    "    def preprocess_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Preprocess the entire dataframe.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): Input dataframe with 'abstract' and 'results' columns\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: Preprocessed dataframe\n",
    "        \"\"\"\n",
    "        # change columns names depending which csv file you are using\n",
    "        df['clean_abstract'] = df['abstract'].apply(self.clean_text).apply(self.remove_stopwords)\n",
    "        df['clean_full_text'] = df['full_text'].apply(self.clean_text).apply(self.remove_stopwords)\n",
    "        \n",
    "        # Combine cleaned abstract and results or full_texts depending on which csv you are using\n",
    "        df['combined_text'] = df['clean_abstract'] + ' ' + df['clean_full_text']\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def prepare_for_model(self, text: str, max_length: int = 512) -> str:\n",
    "        \"\"\"\n",
    "        Prepare text for model input, truncating if necessary.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Input text\n",
    "            max_length (int): Maximum number of words\n",
    "        \n",
    "        Returns:\n",
    "            str: Prepared text\n",
    "        \"\"\"\n",
    "        words = text.split()\n",
    "        if len(words) > max_length:\n",
    "            return ' '.join(words[:max_length])\n",
    "        return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample preprocessed and model-ready text:\n",
      "case report explores challenges associated management chronic medical diseases patients psychiatric disorders patient 36-year-old female patient diagnosed aids multiple secondary infections major depr...\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "def main():\n",
    "    # Load your DataFrame\n",
    "    df = pd.read_csv('pmc_dataset.csv')  # choose a csv file\n",
    "    \n",
    "    # Initialize the preprocessor\n",
    "    preprocessor = STIDataPreprocessor()\n",
    "    \n",
    "    # Preprocess the data\n",
    "    processed_df = preprocessor.preprocess_dataframe(df)\n",
    "    \n",
    "    # Prepare a sample for model input\n",
    "    sample_text = processed_df['combined_text'].iloc[0]\n",
    "    model_ready_text = preprocessor.prepare_for_model(sample_text)\n",
    "    \n",
    "    print(\"Sample preprocessed and model-ready text:\")\n",
    "    print(model_ready_text[:200] + \"...\")  # Print first 200 characters\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
    "\n",
    "class STIChatbot:\n",
    "    def __init__(self, summary_model=\"FalconsAI/medical_summarization\", \n",
    "                 qa_model=\"microsoft/BioGPT\"):\n",
    "        self.preprocessor = STIDataPreprocessor()\n",
    "        self.summary_tokenizer = AutoTokenizer.from_pretrained(summary_model)\n",
    "        self.summary_model = AutoModelForSeq2SeqLM.from_pretrained(summary_model)\n",
    "        self.qa_tokenizer = AutoTokenizer.from_pretrained(qa_model)\n",
    "        self.qa_model = AutoModelForCausalLM.from_pretrained(qa_model)\n",
    "\n",
    "    def preprocess_data(self, df):\n",
    "        return self.preprocessor.preprocess_dataframe(df)\n",
    "\n",
    "    def generate_summary(self, text):\n",
    "        inputs = self.summary_tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "        summary_ids = self.summary_model.generate(\n",
    "            inputs[\"input_ids\"], \n",
    "            max_new_tokens=150,\n",
    "            min_length=40,\n",
    "            length_penalty=2.0,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        return self.summary_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    def answer_question(self, context, question):\n",
    "        prompt = f\"Context: {context}\\nQuestion: {question}\\nAnswer:\"\n",
    "        inputs = self.qa_tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        \n",
    "        # Calculate available tokens for the answer\n",
    "        input_length = inputs[\"input_ids\"].shape[1]\n",
    "        max_new_tokens = min(100, 1024 - input_length)  # Assuming 1024 is the model's maximum context length\n",
    "        \n",
    "        output = self.qa_model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            num_return_sequences=1,\n",
    "            do_sample=True,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return self.qa_tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What are the main symptoms of chlamydia?\n",
      "A: Context: background management chronic medical diseases patients psychiatric disorders patient 36-year-old female patient diagnosed aids multiple secondary infections major depressive disorder anxiety polysubstance abuse simultaneous occurrence physical mental health conditions presents unique obstacles managing chronic medical diseases goal report discuss patients medical history psychosocial factors interventions outcomes provide insights future patient care report also illuminate relationship psychiatric disorders diminished health maintenance human immunodeficiency virus hiv predominantly sexually transmitted infection destroys cd4 + lymphocyte cells acquired immunodeficiency syndrome aids final disease stage original viral infection diagnosis and / or presence aids-defining illness complex treatment plan patient included management psychiatric medical diagnoses upon admission patient given diphenhydramine Question: What are the main symptoms of chlamydia? Answer: background management chronic medical diseases patient psychiatric disorders patient psychiatric comorbidities patient psychiatric comorbidities patient medical history psychosocial factors interventions outcomes offer insights into patient care report also show chlamydia is a major infection decreasing her life expectancy.\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "chatbot = STIChatbot()\n",
    "df = pd.read_csv('pmc_dataset.csv')\n",
    "processed_df = chatbot.preprocess_data(df)\n",
    "\n",
    "# Example usage\n",
    "context = processed_df['combined_text'].iloc[0]\n",
    "summary = chatbot.generate_summary(context)\n",
    "question = \"What are the main symptoms of chlamydia?\"\n",
    "answer = chatbot.answer_question(summary, question)\n",
    "print(f\"Q: {question}\\nA: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
