{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for machine learning and deep learning\n",
    "import transformers  # Hugging Face library for working with pre-trained models\n",
    "import torch        # PyTorch library for tensor computations and neural networks\n",
    "import typing       # Library for type hinting and type annotations\n",
    "\n",
    "class MedicalChatbot:\n",
    "    def __init__(self, model_id=\"aaditya/OpenBioLLM-Llama3-70B\"):\n",
    "        \"\"\"\n",
    "        Initialize the medical chatbot with a specific medical language model\n",
    "        \n",
    "        Args:\n",
    "            model_id (str): Identifier for the pre-trained medical language model\n",
    "        \"\"\"\n",
    "        # Create a text generation pipeline using the specified model\n",
    "        self.pipeline = transformers.pipeline(\n",
    "            \"text-generation\",            # Specify the task as text generation\n",
    "            model=model_id,               # Use the specified model from Hugging Face\n",
    "            model_kwargs={\"torch_dtype\": torch.bfloat16},  # Use lower precision for memory efficiency\n",
    "            device=\"auto\",                # Automatically select best available device (CPU/GPU)\n",
    "        )\n",
    "        \n",
    "        # Define a comprehensive system prompt that sets the context for medical interactions\n",
    "        self.system_prompt = (\n",
    "            \"You are an expert and experienced medical professional \"\n",
    "            \"from the healthcare and biomedical domain with extensive \"\n",
    "            \"medical knowledge. Your name is OpenBioLLM, developed by \"\n",
    "            \"Saama AI Labs. Provide precise, evidence-based medical \"\n",
    "            \"explanations that are scientifically accurate and \"\n",
    "            \"comprehensible to a general audience.\"\n",
    "        )\n",
    "\n",
    "    def generate_response(\n",
    "        self, \n",
    "        user_query: str,           # Type hint for user's input query\n",
    "        max_tokens: int = 256,     # Default maximum response length\n",
    "        temperature: float = 0.1   # Default temperature for response variability\n",
    "    ) -> str:                      # Type hint indicating return is a string\n",
    "        \"\"\"\n",
    "        Generate a medical response to a user's query\n",
    "        \n",
    "        Args:\n",
    "            user_query (str): Medical question or prompt\n",
    "            max_tokens (int): Maximum response length\n",
    "            temperature (float): Controls response randomness/creativity\n",
    "        \n",
    "        Returns:\n",
    "            str: Generated medical response\n",
    "        \"\"\"\n",
    "        # Construct message list with system and user roles\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.system_prompt},  # Set AI's professional context\n",
    "            {\"role\": \"user\", \"content\": user_query}             # Add user's specific query\n",
    "        ]\n",
    "        \n",
    "        # Apply chat template to format messages for the model\n",
    "        prompt = self.pipeline.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,               # Return as string, not tokens\n",
    "            add_generation_prompt=True    # Add markers for response generation\n",
    "        )\n",
    "        \n",
    "        # Define token IDs to terminate generation\n",
    "        terminators = [\n",
    "            self.pipeline.tokenizer.eos_token_id,                 # Standard end-of-sequence token\n",
    "            self.pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")  # Custom end token\n",
    "        ]\n",
    "        \n",
    "        # Generate response using the language model\n",
    "        outputs = self.pipeline(\n",
    "            prompt,\n",
    "            max_new_tokens=max_tokens,    # Limit response length\n",
    "            eos_token_id=terminators,     # Use defined termination tokens\n",
    "            do_sample=True,               # Enable probabilistic sampling\n",
    "            temperature=temperature,       # Control response randomness\n",
    "            top_p=0.9,                    # Nucleus sampling parameter\n",
    "        )\n",
    "        \n",
    "        # Extract and clean the generated response\n",
    "        return outputs[0][\"generated_text\"][len(prompt):].strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of predefined medical questions for testing the model catogorized with dictionaries \n",
    "medical_questions = {\n",
    "    \"Basic Medical Knowledge\": [\n",
    "        \"What are the primary symptoms of type 2 diabetes?\",\n",
    "        \"Explain the pathophysiology of hypertension.\",\n",
    "        \"What are the recommended screening protocols for breast cancer?\"\n",
    "    ],\n",
    "    \"Pharmacological Queries\": [\n",
    "        \"What are the potential side effects of statins?\",\n",
    "        \"How do ACE inhibitors work to manage blood pressure?\",\n",
    "        \"Compare the mechanisms of different antidepressant classes.\"\n",
    "    ],\n",
    "    \"Diagnostic Reasoning\": [\n",
    "        \"What diagnostic tests would you recommend for suspected rheumatoid arthritis?\",\n",
    "        \"Describe the differential diagnosis for chest pain in a 45-year-old male.\"\n",
    "    ],\n",
    "    \"Treatment & Management\": [\n",
    "        \"What are current guidelines for managing type 1 diabetes in adolescents?\",\n",
    "        \"Explain the stages of cancer treatment and potential therapies.\"\n",
    "    ],\n",
    "    \"Specialized Medical Topics\": [\n",
    "        \"How does CRISPR technology potentially impact genetic disease treatment?\",\n",
    "        \"What are the latest advances in immunotherapy for cancer?\"\n",
    "    ],\n",
    "    \"Preventive Medicine\": [\n",
    "        \"What lifestyle modifications can reduce the risk of cardiovascular disease?\",\n",
    "        \"Discuss the importance of vaccination in preventing infectious diseases.\"\n",
    "    ],\n",
    "    \"Specialized Medical Scenarios\": [\n",
    "        \"What are the complications of untreated gestational diabetes?\",\n",
    "        \"Explain the neurological manifestations of multiple sclerosis.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "med_cat = \"Basic Medical Knowledge\" #select the medical category for the user query\n",
    "User_questions = medical_questions[med_cat] #set the users questions to the selected category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to demonstrate the chatbot's functionality\n",
    "def main():\n",
    "    # Create an instance of the MedicalChatbot\n",
    "    chatbot = MedicalChatbot()\n",
    "    \n",
    "    # Iterate through a subset of medical questions\n",
    "    for question in User_questions:  # Test the selected questions\n",
    "        # Print the current query\n",
    "        print(f\"\\nü©∫ Query: {question}\")\n",
    "        \n",
    "        # Generate and print the response\n",
    "        response = chatbot.generate_response(question)\n",
    "        print(f\"üìù Response: {response}\")\n",
    "        \n",
    "        # Print a separator for readability\n",
    "        print(\"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the main function only runs if the script is executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
