{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for machine learning and deep learning\n",
    "import transformers  # Hugging Face library for working with pre-trained models\n",
    "import torch        # PyTorch library for tensor computations and neural networks\n",
    "import typing       # Library for type hinting and type annotations\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedicalChatbot:\n",
    "    # Dictionary mapping medical question categories to tailored system prompts\n",
    "    category_prompts = {\n",
    "        \"Basic Medical Knowledge\": (\n",
    "            \"You are an experienced medical professional specializing in general medical knowledge. \"\n",
    "            \"Provide detailed and comprehensible answers to basic medical questions, ensuring accuracy and clarity.\"\n",
    "        ),\n",
    "        \"Pharmacological Queries\": (\n",
    "            \"You are a pharmacology expert with extensive knowledge of drugs, their mechanisms, and side effects. \"\n",
    "            \"Provide precise and evidence-based information about medications and treatments.\"\n",
    "        ),\n",
    "        \"Diagnostic Reasoning\": (\n",
    "            \"You are a diagnostic expert proficient in identifying medical conditions. \"\n",
    "            \"Offer clear and methodical guidance for diagnostic reasoning and differential diagnoses.\"\n",
    "        ),\n",
    "        \"Treatment & Management\": (\n",
    "            \"You are a specialist in medical treatment and patient management strategies. \"\n",
    "            \"Provide comprehensive explanations of treatment guidelines and management protocols.\"\n",
    "        ),\n",
    "        \"Specialized Medical Topics\": (\n",
    "            \"You are an expert in advanced medical research and innovations. \"\n",
    "            \"Discuss specialized medical topics with a focus on the latest scientific advances.\"\n",
    "        ),\n",
    "        \"Preventive Medicine\": (\n",
    "            \"You are a preventive medicine specialist with expertise in lifestyle modifications and public health. \"\n",
    "            \"Explain preventive strategies and their importance in reducing disease risk.\"\n",
    "        ),\n",
    "        \"Specialized Medical Scenarios\": (\n",
    "            \"You are a clinical specialist adept at handling unique and complex medical scenarios. \"\n",
    "            \"Provide nuanced insights into complications and specialized conditions.\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Fallback system prompt for undefined categories\n",
    "    default_prompt = (\n",
    "        \"You are an expert and experienced medical professional with extensive medical knowledge. \"\n",
    "        \"Provide precise, evidence-based medical explanations that are scientifically accurate and comprehensible to a general audience.\"\n",
    "    )\n",
    "\n",
    "    def __init__(self, model_id=\"aaditya/OpenBioLLM-Llama3-70B\"):\n",
    "        \"\"\"\n",
    "        Initialize the medical chatbot with a specific medical language model\n",
    "        \n",
    "        Args:\n",
    "            model_id (str): Identifier for the pre-trained medical language model\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            # Import logging for better error tracking and debugging\n",
    "            import logging\n",
    "\n",
    "            # Configure logging\n",
    "            logging.basicConfig(level=logging.INFO, \n",
    "                                format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "            self.logger = logging.getLogger(__name__)\n",
    "\n",
    "            # Log model initialization\n",
    "            self.logger.info(f\"Initializing Medical Chatbot with model: {model_id}\")\n",
    "\n",
    "            # Create a text generation pipeline using the specified model\n",
    "            self.pipeline = transformers.pipeline(\n",
    "                \"text-generation\",            # Specify the task as text generation\n",
    "                model=model_id,               # Use the specified model from Hugging Face\n",
    "                model_kwargs={\"torch_dtype\": torch.bfloat16},  # Use lower precision for memory efficiency\n",
    "                device=\"auto\",                # Automatically select best available device (CPU/GPU)\n",
    "            )\n",
    "        # Log successful model loading\n",
    "            self.logger.info(\"Model successfully initialized\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # More robust error handling\n",
    "            self.logger.error(f\"Failed to initialize model: {e}\")\n",
    "            raise RuntimeError(f\"Model initialization failed: {e}\")\n",
    "        \n",
    "\n",
    "        # Default medical category (can be dynamically updated later)\n",
    "        self.med_cat = \"Basic Medical Knowledge\"\n",
    "\n",
    "        # Fetch the initial system prompt based on the category\n",
    "        self.system_prompt = self.category_prompts.get(self.med_cat, self.default_prompt)\n",
    "\n",
    "    def set_category(self, category: str):\n",
    "        \"\"\"\n",
    "        Set the medical category dynamically and update the system prompt.\n",
    "        \n",
    "        Args:\n",
    "            category (str): New medical category to set.\n",
    "        \"\"\"\n",
    "        self.med_cat = category\n",
    "        self.system_prompt = self.category_prompts.get(self.med_cat, self.default_prompt)\n",
    "\n",
    "    def generate_response(\n",
    "        self, \n",
    "        user_query: str,           # Type hint for user's input query\n",
    "        max_tokens: int = 256,     # Default maximum response length\n",
    "        temperature: float = 0.1,   # Default temperature for response variability\n",
    "        safety_threshold: float = 0.7  # New parameter for response safety\n",
    "    ) -> str:                      # Type hint indicating return is a string\n",
    "        \"\"\"\n",
    "        Generate a medical response to a user's query\n",
    "        \n",
    "        Args:\n",
    "            user_query (str): Medical question or prompt\n",
    "            max_tokens (int): Maximum response length\n",
    "            temperature (float): Controls response randomness/creativity\n",
    "        \n",
    "        Returns:\n",
    "            str: Generated medical response\n",
    "        \"\"\"\n",
    "\n",
    "        # Input validation\n",
    "        if not user_query or not isinstance(user_query, str):\n",
    "            raise ValueError(\"User query must be a non-empty string\")\n",
    "        \n",
    "        # Ensure temperature is within a reasonable range\n",
    "        temperature = max(0.0, min(temperature, 1.0))\n",
    "\n",
    "\n",
    "        try:\n",
    "            # Construct message list with system and user roles\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": self.system_prompt},  # System prompt defining AI's role\n",
    "                {\"role\": \"user\", \"content\": user_query}             # User query for the model\n",
    "            ]\n",
    "\n",
    "            # Apply chat template to format messages for the model\n",
    "            prompt = self.pipeline.tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                tokenize=False,               # Return as string, not tokens\n",
    "                add_generation_prompt=True    # Add markers for response generation\n",
    "            )\n",
    "\n",
    "            # Define token IDs to terminate generation\n",
    "            terminators = [\n",
    "                self.pipeline.tokenizer.eos_token_id,                 # Standard end-of-sequence token\n",
    "                self.pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")  # Custom end token\n",
    "            ]\n",
    "\n",
    "            # Generate response using the language model\n",
    "            outputs = self.pipeline(\n",
    "                prompt,\n",
    "                max_new_tokens=max_tokens,    # Limit response length\n",
    "                eos_token_id=terminators,     # Use defined termination tokens\n",
    "                do_sample=True,               # Enable probabilistic sampling\n",
    "                temperature=temperature,       # Control response randomness\n",
    "                top_p=0.9,                    # Nucleus sampling parameter\n",
    "                top_k=50,  # Added top-k sampling for more controlled generation\n",
    "            )\n",
    "\n",
    "            # Extract and clean the generated response\n",
    "            generated_text = outputs[0][\"generated_text\"][len(prompt):].strip()\n",
    "\n",
    "            # Optional: Simple safety filtering (very basic, consider more robust solutions)\n",
    "            if len(generated_text.split()) / max_tokens > safety_threshold:\n",
    "                self.logger.warning(\"Generated response might exceed safety threshold\")\n",
    "\n",
    "            return generated_text\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Comprehensive error logging\n",
    "            self.logger.error(f\"Response generation failed: {e}\")\n",
    "            return f\"An error occurred while processing your query: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of predefined medical questions for testing the model catogorized with dictionaries \n",
    "medical_questions = {\n",
    "    \"Basic Medical Knowledge\": [\n",
    "        \"What are the primary symptoms of type 2 diabetes?\",\n",
    "        \"Explain the pathophysiology of hypertension.\",\n",
    "        \"What are the recommended screening protocols for breast cancer?\"\n",
    "    ],\n",
    "    \"Pharmacological Queries\": [\n",
    "        \"What are the potential side effects of statins?\",\n",
    "        \"How do ACE inhibitors work to manage blood pressure?\",\n",
    "        \"Compare the mechanisms of different antidepressant classes.\"\n",
    "    ],\n",
    "    \"Diagnostic Reasoning\": [\n",
    "        \"What diagnostic tests would you recommend for suspected rheumatoid arthritis?\",\n",
    "        \"Describe the differential diagnosis for chest pain in a 45-year-old male.\"\n",
    "    ],\n",
    "    \"Treatment & Management\": [\n",
    "        \"What are current guidelines for managing type 1 diabetes in adolescents?\",\n",
    "        \"Explain the stages of cancer treatment and potential therapies.\"\n",
    "    ],\n",
    "    \"Specialized Medical Topics\": [\n",
    "        \"How does CRISPR technology potentially impact genetic disease treatment?\",\n",
    "        \"What are the latest advances in immunotherapy for cancer?\"\n",
    "    ],\n",
    "    \"Preventive Medicine\": [\n",
    "        \"What lifestyle modifications can reduce the risk of cardiovascular disease?\",\n",
    "        \"Discuss the importance of vaccination in preventing infectious diseases.\"\n",
    "    ],\n",
    "    \"Specialized Medical Scenarios\": [\n",
    "        \"What are the complications of untreated gestational diabetes?\",\n",
    "        \"Explain the neurological manifestations of multiple sclerosis.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "med_cat = \"Basic Medical Knowledge\" #select the medical category for the user query\n",
    "User_questions = medical_questions[med_cat] #set the users questions to the selected category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to demonstrate the chatbot's functionality\n",
    "def main():\n",
    "    # Create an instance of the MedicalChatbot\n",
    "    chatbot = MedicalChatbot()\n",
    "    \n",
    "    # Iterate through a subset of medical questions\n",
    "    for question in User_questions:  # Test the selected questions\n",
    "        # Print the current query\n",
    "        print(f\"\\nü©∫ Query: {question}\")\n",
    "        \n",
    "        # Generate and print the response\n",
    "        response = chatbot.generate_response(question)\n",
    "        print(f\"üìù Response: {response}\")\n",
    "        \n",
    "        # Print a separator for readability\n",
    "        print(\"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the main function only runs if the script is executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
