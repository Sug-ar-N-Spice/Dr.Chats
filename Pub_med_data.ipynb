{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pymed import PubMed\n",
    "pubmed = PubMed(tool=\"MyTool\", email=\"tyzwhitt@gmail.com\")\n",
    "results = pubmed.query(\"sexually transmitted infections\", max_results=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "400 Client Error: Bad Request for url: https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?tool=MyTool&email=tyzwhitt%40gmail.com&db=pubmed&id=39339913&id=39339899&id=39339898&id=39339869&id=39339868&id=39339859&id=39339857&id=39339852&id=39339850&id=39339847&id=39339846&id=39339844&id=39339842&id=39339834&id=39339673&id=39338924&id=39338574&id=39338032&id=39338016&id=39338008&id=39336591&id=39335513&id=39334938&id=39334472&id=39334470&id=39334328&id=39334289&id=39334144&id=39334111&id=39334074&id=39334069&id=39334034&id=39334032&id=39334014&id=39334013&id=39334011&id=39333961&id=39333960&id=39333946&id=39333935&id=39333924&id=39333912&id=39333475&id=39333233&id=39332869&id=39331953&id=39331848&id=39331816&id=39331650&id=39331616&id=39331464&id=39331393&id=39331212&id=39331126&id=39331007&id=39330027&id=39329696&id=39328414&id=39327860&id=39327822&id=39327804&id=39327034&id=39326782&id=39325924&id=39325811&id=39325776&id=39325764&id=39325123&id=39325120&id=39325008&id=39325007&id=39325006&id=39325005&id=39325004&id=39324704&id=39324693&id=39324676&id=39324549&id=39324408&id=39324163&id=39324141&id=39324108&id=39323905&id=39323078&id=39322418&id=39321646&id=39321242&id=39321241&id=39321205&id=39321175&id=39321171&id=39321072&id=39320323&id=39319873&id=39319814&id=39319744&id=39319622&id=39319555&id=39319309&id=39317928&id=39317706&id=39317654&id=39317508&id=39317499&id=39317498&id=39316784&id=39316154&id=39316125&id=39316078&id=39316045&id=39316041&id=39316036&id=39316034&id=39315943&id=39315334&id=39315333&id=39315069&id=39315066&id=39314941&id=39314930&id=39314093&id=39313453&id=39313283&id=39313262&id=39312925&id=39312771&id=39312589&id=39312538&id=39312338&id=39311733&id=39311353&id=39311101&id=39310786&id=39309762&id=39309258&id=39308823&id=39308785&id=39307697&id=39306385&id=39306359&id=39305907&id=39305818&id=39298160&id=39298115&id=39305374&id=39305093&id=39304906&id=39304894&id=39304838&id=39304666&id=39304605&id=39304239&id=39304236&id=39304230&id=39302204&id=39302149&id=39302054&id=39301743&id=39301685&id=39301675&id=39301593&id=39302927&id=39302639&id=39302585&id=39302045&id=39301670&id=39300442&id=39300441&id=39300436&id=39300364&id=39300354&id=39299714&id=39298907&id=39298465&id=39298375&id=39296834&id=39296520&id=39296438&id=39295873&id=39295869&id=39295867&id=39295482&id=39295131&id=39295119&id=39294815&id=39294779&id=39294641&id=39293346&id=39292732&id=39292703&id=39292353&id=39292318&id=39292129&id=39292108&id=39292039&id=39290915&id=39290079&id=39290078&id=39289724&id=39289649&id=39289508&id=39289490&id=39289479&id=39289007&id=39288983&id=39288982&id=39288978&id=39288789&id=39288680&id=39288251&id=39288155&id=39288118&id=39287735&id=39287566&id=39287554&id=39287547&id=39287406&id=39287121&id=39286972&id=39286864&id=39286717&id=39285796&id=39285366&id=39285344&id=39285273&id=39284893&id=39284339&id=39284338&id=39284166&id=39283978&id=39283906&id=39282969&id=39282633&id=39282536&id=39282250&id=39280832&id=39280293&id=39280282&id=39279129&id=39279002&id=39278923&id=39278908&id=39278674&id=39277945&id=39277892&id=39277747&id=39277660&id=39277590&id=39276681&id=39268680&retmode=xml",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m article \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      4\u001b[0m     article_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabstract\u001b[39m\u001b[38;5;124m'\u001b[39m: [article\u001b[38;5;241m.\u001b[39mabstract],\n\u001b[0;32m      5\u001b[0m                                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m: [article\u001b[38;5;241m.\u001b[39mresults],\n\u001b[0;32m      6\u001b[0m                                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthors\u001b[39m\u001b[38;5;124m'\u001b[39m: [article\u001b[38;5;241m.\u001b[39mauthors],\n\u001b[0;32m      7\u001b[0m                                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m: [article\u001b[38;5;241m.\u001b[39mtitle] })\n\u001b[0;32m      9\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, article_df],ignore_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\tyzwh\\OneDrive\\AI\\bootcamp\\envs\\dev\\lib\\site-packages\\pymed\\api.py:169\u001b[0m, in \u001b[0;36mPubMed._getArticles\u001b[1;34m(self, article_ids)\u001b[0m\n\u001b[0;32m    166\u001b[0m parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m article_ids\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m# Make the request\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/entrez/eutils/efetch.fcgi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    171\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# Parse as XML\u001b[39;00m\n\u001b[0;32m    174\u001b[0m root \u001b[38;5;241m=\u001b[39m xml\u001b[38;5;241m.\u001b[39mfromstring(response)\n",
      "File \u001b[1;32mc:\\Users\\tyzwh\\OneDrive\\AI\\bootcamp\\envs\\dev\\lib\\site-packages\\pymed\\api.py:143\u001b[0m, in \u001b[0;36mPubMed._get\u001b[1;34m(self, url, parameters, output)\u001b[0m\n\u001b[0;32m    140\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, params\u001b[38;5;241m=\u001b[39mparameters)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Check for any errors\u001b[39;00m\n\u001b[1;32m--> 143\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# Add this request to the list of requests made\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requestsMade\u001b[38;5;241m.\u001b[39mappend(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n",
      "File \u001b[1;32mc:\\Users\\tyzwh\\OneDrive\\AI\\bootcamp\\envs\\dev\\lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1016\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1017\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1018\u001b[0m     )\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?tool=MyTool&email=tyzwhitt%40gmail.com&db=pubmed&id=39339913&id=39339899&id=39339898&id=39339869&id=39339868&id=39339859&id=39339857&id=39339852&id=39339850&id=39339847&id=39339846&id=39339844&id=39339842&id=39339834&id=39339673&id=39338924&id=39338574&id=39338032&id=39338016&id=39338008&id=39336591&id=39335513&id=39334938&id=39334472&id=39334470&id=39334328&id=39334289&id=39334144&id=39334111&id=39334074&id=39334069&id=39334034&id=39334032&id=39334014&id=39334013&id=39334011&id=39333961&id=39333960&id=39333946&id=39333935&id=39333924&id=39333912&id=39333475&id=39333233&id=39332869&id=39331953&id=39331848&id=39331816&id=39331650&id=39331616&id=39331464&id=39331393&id=39331212&id=39331126&id=39331007&id=39330027&id=39329696&id=39328414&id=39327860&id=39327822&id=39327804&id=39327034&id=39326782&id=39325924&id=39325811&id=39325776&id=39325764&id=39325123&id=39325120&id=39325008&id=39325007&id=39325006&id=39325005&id=39325004&id=39324704&id=39324693&id=39324676&id=39324549&id=39324408&id=39324163&id=39324141&id=39324108&id=39323905&id=39323078&id=39322418&id=39321646&id=39321242&id=39321241&id=39321205&id=39321175&id=39321171&id=39321072&id=39320323&id=39319873&id=39319814&id=39319744&id=39319622&id=39319555&id=39319309&id=39317928&id=39317706&id=39317654&id=39317508&id=39317499&id=39317498&id=39316784&id=39316154&id=39316125&id=39316078&id=39316045&id=39316041&id=39316036&id=39316034&id=39315943&id=39315334&id=39315333&id=39315069&id=39315066&id=39314941&id=39314930&id=39314093&id=39313453&id=39313283&id=39313262&id=39312925&id=39312771&id=39312589&id=39312538&id=39312338&id=39311733&id=39311353&id=39311101&id=39310786&id=39309762&id=39309258&id=39308823&id=39308785&id=39307697&id=39306385&id=39306359&id=39305907&id=39305818&id=39298160&id=39298115&id=39305374&id=39305093&id=39304906&id=39304894&id=39304838&id=39304666&id=39304605&id=39304239&id=39304236&id=39304230&id=39302204&id=39302149&id=39302054&id=39301743&id=39301685&id=39301675&id=39301593&id=39302927&id=39302639&id=39302585&id=39302045&id=39301670&id=39300442&id=39300441&id=39300436&id=39300364&id=39300354&id=39299714&id=39298907&id=39298465&id=39298375&id=39296834&id=39296520&id=39296438&id=39295873&id=39295869&id=39295867&id=39295482&id=39295131&id=39295119&id=39294815&id=39294779&id=39294641&id=39293346&id=39292732&id=39292703&id=39292353&id=39292318&id=39292129&id=39292108&id=39292039&id=39290915&id=39290079&id=39290078&id=39289724&id=39289649&id=39289508&id=39289490&id=39289479&id=39289007&id=39288983&id=39288982&id=39288978&id=39288789&id=39288680&id=39288251&id=39288155&id=39288118&id=39287735&id=39287566&id=39287554&id=39287547&id=39287406&id=39287121&id=39286972&id=39286864&id=39286717&id=39285796&id=39285366&id=39285344&id=39285273&id=39284893&id=39284339&id=39284338&id=39284166&id=39283978&id=39283906&id=39282969&id=39282633&id=39282536&id=39282250&id=39280832&id=39280293&id=39280282&id=39279129&id=39279002&id=39278923&id=39278908&id=39278674&id=39277945&id=39277892&id=39277747&id=39277660&id=39277590&id=39276681&id=39268680&retmode=xml"
     ]
    }
   ],
   "source": [
    "df =pd.DataFrame()\n",
    "\n",
    "for article in list(results):\n",
    "    article_df = pd.DataFrame({'abstract': [article.abstract],\n",
    "                                      'results': [article.results],\n",
    "                                        'authors': [article.authors],\n",
    "                                        'title': [article.title] })\n",
    "\n",
    "    df = pd.concat([df, article_df],ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "output_file = \"sti_dataset.csv\"\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human papillomavirus (HPV) infections are a significant public health concern as they cause various cancers, including those of the cervix, vulva, vagina, anus, penis, and oropharynx, in both women and men.\n",
      "Individuals with immune-mediated inflammatory diseases, particularly systemic lupus erythematosus, have an increased risk of developing persistent HPV infection and subsequent precancerous lesions due to their immunosuppression.\n",
      "Vaccination and screening for precancerous lesions are 2 central management strategies that must be implemented in patients with immune-mediated inflammatory diseases. Although HPV vaccination has been proven to be safe and effective in these patients, coverage remains low and should be encouraged. Screening for cervical cancer should be more widely implemented in this population, as recommended in guidelines for other immunosuppressed patients.\n",
      "Catch-up vaccination, vaginal self-sampling screening for HPV detection, and therapeutic vaccination are new options that should be considered.\n"
     ]
    }
   ],
   "source": [
    "print(df['abstract'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df['results'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "* preprocess data before using transformers (skip for now)\n",
    "* explore transformers and stacking options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from typing import List, Dict\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "class STIDataPreprocessor:\n",
    "    \"\"\"\n",
    "    Preprocessor for Sexually Transmitted Infections (STI) medical data.\n",
    "    \n",
    "    This class handles cleaning, normalization, and preparation of text data\n",
    "    related to STIs for use in a medical chatbot.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the preprocessor with necessary NLTK downloads.\"\"\"\n",
    "        nltk.download('punkt', quiet=True)\n",
    "        nltk.download('stopwords', quiet=True)\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "        # STI-specific terms to keep even if they're in stopwords\n",
    "        self.sti_terms = {'hiv', 'aids', 'std', 'sti', 'hpv', 'hsv'}\n",
    "        self.stop_words = self.stop_words - self.sti_terms\n",
    "\n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Clean and normalize the input text.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Raw input text\n",
    "        \n",
    "        Returns:\n",
    "            str: Cleaned and normalized text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove special characters but keep medical symbols\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s+\\-/%]', '', text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        return text\n",
    "\n",
    "    def remove_stopwords(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Remove stopwords from the text, keeping STI-specific terms.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Input text\n",
    "        \n",
    "        Returns:\n",
    "            str: Text with stopwords removed\n",
    "        \"\"\"\n",
    "        words = word_tokenize(text)\n",
    "        filtered_words = [word for word in words if word.lower() not in self.stop_words]\n",
    "        return ' '.join(filtered_words)\n",
    "\n",
    "    def preprocess_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Preprocess the entire dataframe.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): Input dataframe with 'abstract' and 'results' columns\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: Preprocessed dataframe\n",
    "        \"\"\"\n",
    "        df['clean_abstract'] = df['abstract'].apply(self.clean_text).apply(self.remove_stopwords)\n",
    "        df['clean_results'] = df['results'].apply(self.clean_text).apply(self.remove_stopwords)\n",
    "        \n",
    "        # Combine cleaned abstract and results\n",
    "        df['combined_text'] = df['clean_abstract'] + ' ' + df['clean_results']\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def prepare_for_model(self, text: str, max_length: int = 512) -> str:\n",
    "        \"\"\"\n",
    "        Prepare text for model input, truncating if necessary.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Input text\n",
    "            max_length (int): Maximum number of words\n",
    "        \n",
    "        Returns:\n",
    "            str: Prepared text\n",
    "        \"\"\"\n",
    "        words = text.split()\n",
    "        if len(words) > max_length:\n",
    "            return ' '.join(words[:max_length])\n",
    "        return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample preprocessed and model-ready text:\n",
      "human papillomavirus hpv infections significant public health concern cause various cancers including cervix vulva vagina anus penis oropharynx women men individuals immune-mediated inflammatory disea...\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "def main():\n",
    "    # Load your DataFrame\n",
    "    df = pd.read_csv('sti_dataset.csv')  # Replace with your actual data file\n",
    "    \n",
    "    # Initialize the preprocessor\n",
    "    preprocessor = STIDataPreprocessor()\n",
    "    \n",
    "    # Preprocess the data\n",
    "    processed_df = preprocessor.preprocess_dataframe(df)\n",
    "    \n",
    "    # Prepare a sample for model input\n",
    "    sample_text = processed_df['combined_text'].iloc[0]\n",
    "    model_ready_text = preprocessor.prepare_for_model(sample_text)\n",
    "    \n",
    "    print(\"Sample preprocessed and model-ready text:\")\n",
    "    print(model_ready_text[:200] + \"...\")  # Print first 200 characters\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
    "\n",
    "class STIChatbot:\n",
    "    def __init__(self, summary_model=\"FalconsAI/medical_summarization\", \n",
    "                 qa_model=\"microsoft/BioGPT\"):\n",
    "        self.preprocessor = STIDataPreprocessor()\n",
    "        self.summary_tokenizer = AutoTokenizer.from_pretrained(summary_model)\n",
    "        self.summary_model = AutoModelForSeq2SeqLM.from_pretrained(summary_model)\n",
    "        self.qa_tokenizer = AutoTokenizer.from_pretrained(qa_model)\n",
    "        self.qa_model = AutoModelForCausalLM.from_pretrained(qa_model)\n",
    "\n",
    "    def preprocess_data(self, df):\n",
    "        return self.preprocessor.preprocess_dataframe(df)\n",
    "\n",
    "    def generate_summary(self, text):\n",
    "        inputs = self.summary_tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "        summary_ids = self.summary_model.generate(\n",
    "            inputs[\"input_ids\"], \n",
    "            max_new_tokens=150,\n",
    "            min_length=40,\n",
    "            length_penalty=2.0,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        return self.summary_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    def answer_question(self, context, question):\n",
    "        prompt = f\"Context: {context}\\nQuestion: {question}\\nAnswer:\"\n",
    "        inputs = self.qa_tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        \n",
    "        # Calculate available tokens for the answer\n",
    "        input_length = inputs[\"input_ids\"].shape[1]\n",
    "        max_new_tokens = min(100, 1024 - input_length)  # Assuming 1024 is the model's maximum context length\n",
    "        \n",
    "        output = self.qa_model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            num_return_sequences=1,\n",
    "            do_sample=True,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return self.qa_tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What are the main symptoms of chlamydia?\n",
      "A: Context: human papillomavirus hpv infections significant public health concern cause various cancers including cervix vulva vagina anus penis oropharynx women men individuals immune-mediated inflammatory diseases particularly systemic lupus erythematosus increased risk developing persistent hpv infection subsequent precancerous lesions due immunosuppressed patients catch-up vaccination screening precancerous lesions 2 central management strategies must implemented patients immune-mediated inflammatory diseases although hpv vaccination proven safe effective patients coverage remains low encouraged screening cervical cancer widely implemented population recommended guidelines immunosuppressed patients catch-up vaccination vaginal self-sampling screening Question: What are the main symptoms of chlamydia? Answer: it is likely that patients with genital herpes can develop cervical cancer.\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "chatbot = STIChatbot()\n",
    "df = pd.read_csv('sti_dataset.csv')\n",
    "processed_df = chatbot.preprocess_data(df)\n",
    "\n",
    "# Example usage\n",
    "context = processed_df['combined_text'].iloc[0]\n",
    "summary = chatbot.generate_summary(context)\n",
    "question = \"What are the main symptoms of chlamydia?\"\n",
    "answer = chatbot.answer_question(summary, question)\n",
    "print(f\"Q: {question}\\nA: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tyzwh\\OneDrive\\AI\\bootcamp\\envs\\dev\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8307dfa8fe54c13861f0ef0d9c557e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tyzwh\\OneDrive\\AI\\bootcamp\\envs\\dev\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tyzwh\\.cache\\huggingface\\hub\\models--FalconsAI--medical_summarization. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd424208d0bd4968bfadbf338c5cc928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10b9d7897bb4a658e34541f364081ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8610b13f94d144c1b1addf902bd55564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2e990c2ee742a09283d63dd42e72e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec86db21931544c5bd340531a9d0870d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": " `args[0]`: None have the wrong format. The should be either of type `str` or type `list`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m summarizer \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummarization\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFalconsAI/medical_summarization\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Summarize abstract text\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary_abstract\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mabstract\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msummarizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msummary_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tyzwh\\OneDrive\\AI\\bootcamp\\envs\\dev\\lib\\site-packages\\pandas\\core\\series.py:4915\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4781\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4782\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4788\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4791\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4906\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4907\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4908\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4909\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4913\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4915\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tyzwh\\OneDrive\\AI\\bootcamp\\envs\\dev\\lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tyzwh\\OneDrive\\AI\\bootcamp\\envs\\dev\\lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\tyzwh\\OneDrive\\AI\\bootcamp\\envs\\dev\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tyzwh\\OneDrive\\AI\\bootcamp\\envs\\dev\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      4\u001b[0m summarizer \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummarization\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFalconsAI/medical_summarization\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Summarize abstract text\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary_abstract\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabstract\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43msummarizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary_text\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\tyzwh\\OneDrive\\AI\\bootcamp\\envs\\dev\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:274\u001b[0m, in \u001b[0;36mSummarizationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    251\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;124;03m    Summarize the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m          ids of the summary.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tyzwh\\OneDrive\\AI\\bootcamp\\envs\\dev\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:167\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    139\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;124;03m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 167\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(el, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[0;32m    172\u001b[0m     ):\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "File \u001b[1;32mc:\\Users\\tyzwh\\OneDrive\\AI\\bootcamp\\envs\\dev\\lib\\site-packages\\transformers\\pipelines\\base.py:1268\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1261\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1262\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         )\n\u001b[0;32m   1266\u001b[0m     )\n\u001b[0;32m   1267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tyzwh\\OneDrive\\AI\\bootcamp\\envs\\dev\\lib\\site-packages\\transformers\\pipelines\\base.py:1274\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m-> 1274\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m   1275\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1276\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n",
      "File \u001b[1;32mc:\\Users\\tyzwh\\OneDrive\\AI\\bootcamp\\envs\\dev\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:177\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.preprocess\u001b[1;34m(self, inputs, truncation, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, truncation\u001b[38;5;241m=\u001b[39mTruncationStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_TRUNCATE, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 177\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_and_tokenize(inputs, truncation\u001b[38;5;241m=\u001b[39mtruncation, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n",
      "File \u001b[1;32mc:\\Users\\tyzwh\\OneDrive\\AI\\bootcamp\\envs\\dev\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:129\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline._parse_and_tokenize\u001b[1;34m(self, truncation, *args)\u001b[0m\n\u001b[0;32m    127\u001b[0m     padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `args[0]`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m have the wrong format. The should be either of type `str` or type `list`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    131\u001b[0m     )\n\u001b[0;32m    132\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(\u001b[38;5;241m*\u001b[39margs, padding\u001b[38;5;241m=\u001b[39mpadding, truncation\u001b[38;5;241m=\u001b[39mtruncation, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# This is produced by tokenizers but is an invalid generate kwargs\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m:  `args[0]`: None have the wrong format. The should be either of type `str` or type `list`"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Example: Use a pre-trained transformer model for text summarization\n",
    "summarizer = pipeline(\"summarization\", model=\"FalconsAI/medical_summarization\")\n",
    "\n",
    "# Summarize abstract text\n",
    "processed_df['combined_text'] = df['abstract'].apply(lambda x: summarizer(x)[0]['summary_text'])\n",
    "\n",
    "# You can do the same for results column\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
